{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HnnhsF2p9bbc"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVcLaPl-9ikk"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "\n",
    "            nn.Conv2d(4, 4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "\n",
    "            nn.Conv2d(4, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(0.01),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(8, 12, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(12),\n",
    "\n",
    "            nn.Conv2d(12, 12, 3, padding= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(12),\n",
    "\n",
    "            nn.Conv2d(12, 16, 3, padding= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(16, 20, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(20),\n",
    "\n",
    "            nn.Conv2d(20, 10, 3),\n",
    "\n",
    "            nn.AvgPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 10)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pu-H1Jwk9k27",
    "outputId": "371eaab9-3b47-4f68-87a5-1b0570b85687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 28, 28]              40\n",
      "              ReLU-2            [-1, 4, 28, 28]               0\n",
      "       BatchNorm2d-3            [-1, 4, 28, 28]               8\n",
      "            Conv2d-4            [-1, 4, 28, 28]             148\n",
      "              ReLU-5            [-1, 4, 28, 28]               0\n",
      "       BatchNorm2d-6            [-1, 4, 28, 28]               8\n",
      "            Conv2d-7            [-1, 8, 28, 28]             296\n",
      "              ReLU-8            [-1, 8, 28, 28]               0\n",
      "       BatchNorm2d-9            [-1, 8, 28, 28]              16\n",
      "          Dropout-10            [-1, 8, 28, 28]               0\n",
      "        MaxPool2d-11            [-1, 8, 14, 14]               0\n",
      "           Conv2d-12           [-1, 12, 14, 14]             876\n",
      "             ReLU-13           [-1, 12, 14, 14]               0\n",
      "      BatchNorm2d-14           [-1, 12, 14, 14]              24\n",
      "           Conv2d-15           [-1, 12, 14, 14]           1,308\n",
      "             ReLU-16           [-1, 12, 14, 14]               0\n",
      "      BatchNorm2d-17           [-1, 12, 14, 14]              24\n",
      "           Conv2d-18           [-1, 16, 14, 14]           1,744\n",
      "             ReLU-19           [-1, 16, 14, 14]               0\n",
      "      BatchNorm2d-20           [-1, 16, 14, 14]              32\n",
      "        MaxPool2d-21             [-1, 16, 7, 7]               0\n",
      "           Conv2d-22             [-1, 20, 5, 5]           2,900\n",
      "             ReLU-23             [-1, 20, 5, 5]               0\n",
      "      BatchNorm2d-24             [-1, 20, 5, 5]              40\n",
      "           Conv2d-25             [-1, 10, 3, 3]           1,810\n",
      "        AvgPool2d-26             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 9,274\n",
      "Trainable params: 9,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.54\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TA4pHCpz9m9m"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.Resize((28, 28)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307), (0.3081))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Create a validation/test set from the training data\n",
    "train_data, val_data = torch.utils.data.random_split(train_loader.dataset, [50000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvndGPJ_9oqh"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "def test(model, device, test_loader,epoch,optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() \n",
    "            pred = output.argmax(dim=1, keepdim=True)  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"Epoch: {epoch} | Learning Rate: {optimizer.param_groups[0]['lr']:.5f} | Test Loss: {test_loss:.4f} | Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlINYnQJ9wYC",
    "outputId": "d8126dba-2b91-4747-d9c2-2daae84d6cde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.017699357122182846 batch_id=390: 100%|██████████| 391/391 [00:57<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Learning Rate: 0.01000 | Test Loss: 0.1066 | Accuracy: 9673/10000 (96.73%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.010867567732930183 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Learning Rate: 0.01000 | Test Loss: 0.0608 | Accuracy: 9807/10000 (98.07%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.11412211507558823 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Learning Rate: 0.01000 | Test Loss: 0.0410 | Accuracy: 9868/10000 (98.68%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.010829591192305088 batch_id=390: 100%|██████████| 391/391 [00:51<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Learning Rate: 0.01000 | Test Loss: 0.0408 | Accuracy: 9878/10000 (98.78%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0012745509156957269 batch_id=390: 100%|██████████| 391/391 [00:51<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Learning Rate: 0.01000 | Test Loss: 0.0394 | Accuracy: 9884/10000 (98.84%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.12232786417007446 batch_id=390: 100%|██████████| 391/391 [00:51<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Learning Rate: 0.01000 | Test Loss: 0.0413 | Accuracy: 9879/10000 (98.79%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.08515532314777374 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Learning Rate: 0.01000 | Test Loss: 0.0408 | Accuracy: 9870/10000 (98.70%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05383814126253128 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Learning Rate: 0.01000 | Test Loss: 0.0334 | Accuracy: 9890/10000 (98.90%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.006957699544727802 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Learning Rate: 0.01000 | Test Loss: 0.0303 | Accuracy: 9894/10000 (98.94%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.010455933399498463 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Learning Rate: 0.01000 | Test Loss: 0.0442 | Accuracy: 9891/10000 (98.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02792229875922203 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Learning Rate: 0.01000 | Test Loss: 0.0296 | Accuracy: 9913/10000 (99.13%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0003698678337968886 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Learning Rate: 0.01000 | Test Loss: 0.0391 | Accuracy: 9896/10000 (98.96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0013028652174398303 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Learning Rate: 0.01000 | Test Loss: 0.0471 | Accuracy: 9862/10000 (98.62%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.011150670237839222 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Learning Rate: 0.01000 | Test Loss: 0.0384 | Accuracy: 9895/10000 (98.95%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.010984359309077263 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Learning Rate: 0.00100 | Test Loss: 0.0217 | Accuracy: 9943/10000 (99.43%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.004620316904038191 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Learning Rate: 0.00100 | Test Loss: 0.0210 | Accuracy: 9945/10000 (99.45%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.003626725170761347 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Learning Rate: 0.00100 | Test Loss: 0.0206 | Accuracy: 9945/10000 (99.45%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0006417831173166633 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Learning Rate: 0.00100 | Test Loss: 0.0203 | Accuracy: 9944/10000 (99.44%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0014463502448052168 batch_id=390: 100%|██████████| 391/391 [00:52<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Learning Rate: 0.00100 | Test Loss: 0.0200 | Accuracy: 9949/10000 (99.49%)\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer= optim.Adam(model.parameters(), lr= 0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test_loss = test(model, device, test_loader,epoch,optimizer)\n",
    "    scheduler.step(test_loss)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
